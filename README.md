# any_crawler

クローラーのサンプルです。
汎用性はあまり無いです。
あくまで参考程度でお願いします。
クロールの際は対象サイトの迷惑にならないよう、十分ご注意ください。
当プログラムはオープンにしていますが、利用時のトラブル等に関して、
一切の責任は追えませんのであしからず。自己責任でお願いします。

# how to

## step1

$ vim conf/conf.yml
please show sample.conf.yml

クロール対象のサイトの特性を踏まえてconfファイルを適宜設定ください。
プログラムもきっと変更が必要でしょう。

## step2

$ vim conf/conf.yml
cookie is modified.

ログインは自動にしていません。
手動でログインした後に、セッションを再利用してアクセスする想定でつくってあります。

## step3

$ node main.js
crawler is run.
create target 

クロールを実行します。HTML全体を残してもいいですが、
部分的に抽出するのもよいでしょう。
段階的な抽出が必要な場合もあるでしょう。
サンプルは２段階で取得する想定になっています。
ｔｍｐファイルとして、抽出内容をテキストファイルに出力しています。

## step4

$ vim conf/search_files.txt
$ node search_img.js

ｔｍｐファイルを食って、本命のデータ抽出を実施します。
まるっと再実行ではなく、ターゲットを絞って実行するスタイルとしています。

## step5

以上で終わりです。
取得したデータの整理など、もろもろがんばってください。

end.
